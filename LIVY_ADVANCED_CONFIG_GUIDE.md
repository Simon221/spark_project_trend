# Guide: Configuration Avanc√©e Livy pour le Rattrapage

## üìã Vue d'ensemble

Le syst√®me de rattrapage (recovery) utilise Apache Livy pour soumettre des t√¢ches Spark (JAR) pour r√©cup√©rer des donn√©es manquantes. Les configurations avanc√©es de Livy permettent de contr√¥ler:

- **jars**: JARs suppl√©mentaires √† ajouter au classpath
- **files**: Fichiers √† copier dans le r√©pertoire de travail
- **archives**: Archives (tar/tgz/zip) √† extraire automatiquement
- **pyFiles**: Fichiers Python pour PySpark jobs
- **conf**: Configuration Spark avanc√©e (shuffles, allocation dynamique, etc.)

---

## üîß Configuration dans le fichier `.env`

### 1. LIVY_JARS
Ajoute des JARs suppl√©mentaires au classpath Spark.

**Format**: Chemin HDFS s√©par√©s par des virgules

**Exemple**:
```env
LIVY_JARS=hdfs:///user/sddesigner/lib/commons-lang3-3.12.0.jar,hdfs:///user/sddesigner/lib/jackson-databind-2.15.0.jar
```

**Cas d'usage**:
- D√©pendances du JAR de rattrapage
- Biblioth√®ques communes utilis√©es dans plusieurs projets
- Versions alternatives de librairies (remplace les versions pr√©-incluses)

---

### 2. LIVY_FILES
Copie les fichiers dans le r√©pertoire de travail du job Spark.

**Format**: Chemins HDFS s√©par√©s par des virgules

**Exemple**:
```env
LIVY_FILES=hdfs:///config/app.properties,hdfs:///config/log4j.xml,hdfs:///sql/queries.sql
```

**Cas d'usage**:
- Fichiers de configuration application
- Fichiers de requ√™tes SQL
- Fichiers de logging customis√©s
- Scripts ou donn√©es statiques

---

### 3. LIVY_ARCHIVES
Extrait automatiquement les archives dans le r√©pertoire de travail.

**Format**: Archives (tar.gz, tgz, zip) s√©par√©es par des virgules

**Exemple**:
```env
LIVY_ARCHIVES=hdfs:///archives/dependencies-2024.tar.gz,hdfs:///archives/models.zip
```

**Cas d'usage**:
- Distribuer plusieurs fichiers d'un coup
- Mod√®les ML dans archives compress√©es
- Dossiers entiers de ressources

---

### 4. LIVY_PY_FILES
Ajoute des fichiers Python au path Python du job (pour PySpark).

**Format**: Chemins HDFS s√©par√©s par des virgules

**Exemple**:
```env
LIVY_PY_FILES=hdfs:///python/utils.py,hdfs:///python/transformers.zip
```

**Cas d'usage**:
- Code Python partag√© entre jobs
- Modules personnalis√©s
- ZIP contenant des packages Python

---

### 5. LIVY_CONF
Configuration Spark avanc√©e au format JSON.

**Format**: Objet JSON avec cl√©s de configuration Spark

**Exemple**:
```env
LIVY_CONF={"spark.sql.shuffle.partitions":"200","spark.dynamicAllocation.enabled":"true","spark.executor.heartbeatInterval":"60s"}
```

**Cas d'usage courant**:
```json
{
  "spark.sql.shuffle.partitions": "200",        // Nombre partitions pour shuffle SQL
  "spark.dynamicAllocation.enabled": "true",    // Allocation dynamique des executors
  "spark.shuffle.compress": "true",              // Compression du shuffle
  "spark.executor.heartbeatInterval": "60s",    // Timeout heartbeat
  "spark.sql.adaptive.enabled": "true",         // Query optimization adaptatif
  "spark.broadcast.blockSize": "128m"           // Taille broadcast
}
```

---

## üöÄ Flux d'ex√©cution

### 1. Configuration charg√©e au d√©marrage du serveur
Au d√©marrage de `server.py`, la classe `Config` charge les variables d'environnement:

```python
livy_client = KnoxLivyClient(
    knox_host=Config.KNOX_HOST,
    ad_user=Config.AD_USER,
    ...
    jars=Config.get_livy_jars(),              # Parse LIVY_JARS depuis .env
    files=Config.get_livy_files(),            # Parse LIVY_FILES depuis .env
    conf=Config.get_livy_conf(),              # Parse LIVY_CONF depuis .env
    archives=Config.get_livy_archives(),      # Parse LIVY_ARCHIVES depuis .env
    py_files=Config.get_livy_py_files()       # Parse LIVY_PY_FILES depuis .env
)
```

### 2. Utilisateur clique sur "Faire un rattrapage"
L'interface affiche un formulaire avec:
- **Chemin du JAR**: `jarPath` (ex: `hdfs:///user/sddesigner/recovery.jar`)
- **Arguments**: `jarArgs` (ex: `--date 20240101 --table splio.active`)

### 3. API soumet le JAR √† Livy
L'endpoint `POST /api/v1/recovery/execute-jar` appelle:

```python
result = livy_client.submit_jar(jar_path, jar_args)
```

### 4. KnoxLivyClient construit la payload compl√®te
La m√©thode `submit_jar()` inclut TOUS les configs avanc√©s:

```python
payload = {
    "file": jar_path,                    # JAR principal
    "args": [jar_args],                 # Arguments du JAR
    "driverMemory": "4g",               # Du Config
    "driverCores": 2,                   # Du Config
    "executorMemory": "4g",             # Du Config
    "executorCores": 2,                 # Du Config
    "numExecutors": 4,                  # Du Config
    "queue": "root.datalake",           # Du Config
    "proxyUser": "sddesigner",          # Du Config + PROXY_USER
    "conf": {...},                      # LIVY_CONF pars√© depuis .env
    "archives": [...],                  # LIVY_ARCHIVES pars√© depuis .env
    "files": [...],                     # LIVY_FILES pars√© depuis .env
    "jars": [...]                       # LIVY_JARS pars√© depuis .env
}
```

### 5. Livy re√ßoit et ex√©cute le job
La payload est envoy√©e √† `POST /batches` sur le gateway Knox.

---

## üìù Exemples complets

### Exemple 1: JAR simple sans d√©pendances
```env
LIVY_JARS=
LIVY_FILES=hdfs:///config/app.properties
LIVY_ARCHIVES=
LIVY_PY_FILES=
LIVY_CONF={}
```

### Exemple 2: JAR avec d√©pendances et configuration
```env
LIVY_JARS=hdfs:///libs/commons-lang3-3.12.jar,hdfs:///libs/httpcomponents-client-4.5.jar
LIVY_FILES=hdfs:///config/app.properties,hdfs:///config/secrets.xml
LIVY_ARCHIVES=
LIVY_PY_FILES=
LIVY_CONF={"spark.sql.shuffle.partitions":"500","spark.dynamicAllocation.maxExecutors":"10"}
```

### Exemple 3: R√©cup√©ration avec mod√®le ML
```env
LIVY_JARS=hdfs:///libs/ml-libs.jar
LIVY_FILES=hdfs:///config/database.properties
LIVY_ARCHIVES=hdfs:///models/model-2024.tar.gz
LIVY_PY_FILES=
LIVY_CONF={"spark.executor.memoryOverhead":"1g"}
```

---

## ‚úÖ V√©rification

Pour v√©rifier que les configurations sont bien charg√©es, utilisez:

```python
from src.models.config import Config

print("JARs:", Config.get_livy_jars())
print("Files:", Config.get_livy_files())
print("Archives:", Config.get_livy_archives())
print("PyFiles:", Config.get_livy_py_files())
print("Conf:", Config.get_livy_conf())
```

---

## üîí Notes de s√©curit√©

1. **Chemins HDFS**: Utilisez des chemins absolus HDFS (`hdfs:///...`) ou des chemins r√©seau accessibles
2. **Permissions**: Assurez-vous que l'utilisateur `sddesigner` (PROXY_USER) a acc√®s aux fichiers
3. **Secrets**: Ne commitez JAMAIS le `.env` avec des secrets en Git
4. **Format JSON**: Validez votre JSON dans `LIVY_CONF` avant de red√©marrer le serveur

---

## üìñ Ressources suppl√©mentaires

- [Documentation Livy REST API](https://livy.apache.org/docs/latest/rest-api)
- [Spark Configuration](https://spark.apache.org/docs/latest/configuration.html)
- [Apache Knox Gateway](https://knox.apache.org/)

